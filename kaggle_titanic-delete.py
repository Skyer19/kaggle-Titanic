# -*- coding: utf-8 -*-
"""kaggle Titanic.ipynb


Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wXH7f86ge74pWXNwpFjAWVZ28t1duatG
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir("/content/drive/My Drive/Colab Notebooks")

import numpy as np
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.nn.functional as F
import torchvision
import torch.optim as optim
from torchvision import transforms
from tqdm import *
import matplotlib.pyplot as plt
import copy
from torch.autograd.gradcheck import zero_gradients
import pandas  as pd 
import seaborn as sns
import re
import torch.utils.data as data

test = pd.read_csv("./titanic/test.csv")
train = pd.read_csv("./titanic/train.csv")

train['Embarked'].value_counts()

test['Embarked'].fillna(
    test.Embarked.mode().values[0], inplace=True)

train['Embarked'].fillna(
    test.Embarked.mode().values[0], inplace=True)

train['Age'].describe()

test['Age'].fillna(29.699118, inplace=True)
train['Age'].fillna(29.699118, inplace=True)

test['Fare'].fillna(32.204208, inplace=True)

test.info()

dummy_fields=['Pclass','Sex','Embarked']
for each in dummy_fields:
    dummies= pd.get_dummies(train[each], prefix= each, drop_first=False)
    train = pd.concat([train, dummies], axis=1)
train.head()    

fields_to_drop=['PassengerId', 'Cabin', 'Pclass', 'Name', 'Sex', 'Ticket', 'Embarked']
df=train.drop(fields_to_drop,axis=1)
df.head()

dummy_fields=['Pclass', 'Sex', 'Embarked']
for each in dummy_fields:
    dummies= pd.get_dummies(test[each], prefix= each, drop_first=False)
    test = pd.concat([test, dummies], axis=1)
# train.head()  

fields_to_drop=['PassengerId','Cabin', 'Pclass', 'Name', 'Sex', 'Ticket', 'Embarked']
df_test=test.drop(fields_to_drop,axis=1)
df_test.head()

to_normalize=['Age','Fare']
for each in to_normalize:
    mean, std= df[each].mean(), df[each].std()
    df.loc[:, each]=(df[each]-mean)/std

df.head()

to_normalize=['Age','Fare']
for each in to_normalize:
    mean, std= df_test[each].mean(), df_test[each].std()
    df_test.loc[:, each]=(df_test[each]-mean)/std

df_test.head()

titanic_train_data_X = df.drop(['Survived'], axis=1)
titanic_train_data_Y = df['Survived']
titanic_test_data = df_test

train_data = torch.from_numpy(titanic_train_data_X.values).float()
train_label = torch.from_numpy(titanic_train_data_Y.values).float()
test_data = torch.from_numpy(titanic_test_data.values).float()

import torch
from torch.utils.data import TensorDataset, DataLoader

# 数据封装
train_dataset = TensorDataset(train_data, train_label)
trainLoader = DataLoader(train_dataset, batch_size=4,
                         shuffle=True, num_workers=2)


import torch.nn as nn
import torch.nn.functional as F

# 定义模型
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(titanic_train_data_X.shape[1], 64),
            nn.ReLU(),
            nn.Linear(64, 100),
            nn.ReLU(),
            nn.Linear(100, 2),
            nn.Softmax(dim=1)
        )

    def forward(self, x):
        return self.fc(x)


net = Net()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()  
optimizer = optim.Adam(net.parameters(), lr=0.001)  

import time
start = time.time()
for epoch in range(200):
    running_loss = 0.0
    for i, data in enumerate(trainLoader, 0):
        inputs, labels = data  
        optimizer.zero_grad()  

        outputs = net(inputs)
        loss = criterion(outputs, labels.long())
        loss.backward()  
        optimizer.step()  
        running_loss += loss.item()
        # if i % 20 == 19:
        #     # 每 20 次迭代打印一次信息
        #     print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))
        #     running_loss = 0.0
print('Finish Traning! Total cost time: ', time.time()-start)

correct = 0
total = 0
with torch.no_grad():
    for data in trainLoader:
        inputs, labels = data
        outputs = net(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print('Accuracy of the network on the 10000 test images: %d %%' %
      (correct / total * 100))

output = torch.max(net(test_data),1)[1]

submission = pd.read_csv('./titanic/gender_submission.csv')
submission['Survived'] = output
submission.to_csv('./titanic/gender_submission.csv', index=False)

"""
不同超参数时的正确率
Epoach 200 lr =0.001
*   64  50 2 88%   0.74641
*   40 100 2 87%.  0.76076
*   64 100 2 87%.  0.77033
*   80 100 2 88%.  0.74880
*   64 110 2 87%.  0.76555
*   64 125 2 87%.  0.75837
*   64 150 2 88%.  0.73684

Epoach 200 lr =0.015
*   64 100 2 61%.  0.62200

"""
